\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{salton}
\citation{salton}
\citation{jones}
\citation{jonesfre}
\citation{benn}
\citation{mikw2v}
\citation{melamud}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Data representation using Word Embeddings}{1}{section.2}}
\newlabel{sec:emb}{{2}{1}{Data representation using Word Embeddings}{section.2}{}}
\citation{mikw2v}
\citation{mikngs}
\citation{mikngs}
\citation{melamud}
\citation{dep}
\citation{subs}
\citation{finkel}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Word2Vec}{2}{subsection.2.1}}
\newlabel{sec:w2v}{{2.1}{2}{Word2Vec}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Role of Context Types and Dimentionality in Learning Word Embeddings}{2}{subsection.2.2}}
\newlabel{sec:embdim}{{2.2}{2}{Role of Context Types and Dimentionality in Learning Word Embeddings}{subsection.2.2}{}}
\citation{suts}
\citation{pos}
\citation{suts}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Word2Vec consists of two models as shown above. Every word has representation from both the embeddings\relax }}{3}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:w2v}{{1}{3}{Word2Vec consists of two models as shown above. Every word has representation from both the embeddings\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Advancement of Recurrent Neural Networks in NLP}{3}{section.3}}
\newlabel{sec:seqnlp}{{3}{3}{Advancement of Recurrent Neural Networks in NLP}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Sequence to Sequence Learning with Neural Networks}{3}{subsection.3.1}}
\newlabel{sec:suts}{{3.1}{3}{Sequence to Sequence Learning with Neural Networks}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Encoding:}{4}{section*.2}}
\@writefile{toc}{\contentsline {paragraph}{Decoding:}{4}{section*.3}}
\@writefile{toc}{\contentsline {paragraph}{Difference from standard encoder-decoder models: }{4}{section*.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Multilingual Part-of-Speech Tagging with Bidirectional Long-Short-Term-Memory models with Auxiliary Loss}{4}{subsection.3.2}}
\newlabel{sec:pos}{{3.2}{4}{Multilingual Part-of-Speech Tagging with Bidirectional Long-Short-Term-Memory models with Auxiliary Loss}{subsection.3.2}{}}
\citation{senti}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textit  {Left}: Multi-task Elation HealthLSTM that predicts the tag and frequency class for the next token at every time step. \textit  {Right}: Elation HealthLSTM using characters embeddings + byte embeddings\relax }}{5}{figure.caption.5}}
\newlabel{fig:pos}{{2}{5}{\textit {Left}: Multi-task Elation HealthLSTM that predicts the tag and frequency class for the next token at every time step. \textit {Right}: Elation HealthLSTM using characters embeddings + byte embeddings\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Aspect-Based Sentiment Analysis}{5}{subsection.3.3}}
\newlabel{sec:senti}{{3.3}{5}{Aspect-Based Sentiment Analysis}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Input Preprocessing:}{5}{section*.6}}
\@writefile{toc}{\contentsline {paragraph}{Model:}{5}{section*.7}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Attention based Deep Learning Models for Natural Language Processing}{5}{section.4}}
\newlabel{sec:attention}{{4}{5}{Attention based Deep Learning Models for Natural Language Processing}{section.4}{}}
\citation{bahattn}
\citation{luongatn}
\citation{kadlec}
\citation{bahattn}
\citation{cho}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The hierarchical Elation HealthLSTM model for aspect-based sentiment analysis\relax }}{6}{figure.caption.8}}
\newlabel{fig:senti}{{3}{6}{The hierarchical Elation HealthLSTM model for aspect-based sentiment analysis\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Neural Machine Translation by jointly learning to align and translate}{6}{subsection.4.1}}
\newlabel{sec:bahnmt}{{4.1}{6}{Neural Machine Translation by jointly learning to align and translate}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {paragraph}{RNN Encoder-Decoder: }{6}{section*.9}}
\newlabel{fig:bahatn1}{{\caption@xref {fig:bahatn1}{ on input line 184}}{7}{RNN Encoder-Decoder:}{figure.caption.10}{}}
\newlabel{sub@fig:bahatn1}{{}{7}{RNN Encoder-Decoder:}{figure.caption.10}{}}
\newlabel{fig:bahatn2}{{\caption@xref {fig:bahatn2}{ on input line 191}}{7}{RNN Encoder-Decoder:}{figure.caption.10}{}}
\newlabel{sub@fig:bahatn2}{{a}{7}{RNN Encoder-Decoder:}{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The model and the result from Neural Machine Translation by jointly learning to align and translate\relax }}{7}{figure.caption.10}}
\newlabel{fig:bahatn}{{4}{7}{The model and the result from Neural Machine Translation by jointly learning to align and translate\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {paragraph}{Encoder:}{7}{section*.11}}
\citation{luongatn}
\citation{xuatn}
\@writefile{toc}{\contentsline {paragraph}{Decoder: }{8}{section*.12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Effective Approaches to Attention Based Neural Machine Translation}{8}{subsection.4.2}}
\newlabel{luongatn}{{4.2}{8}{Effective Approaches to Attention Based Neural Machine Translation}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Global Attention Model: }{8}{section*.14}}
\citation{kadlec}
\citation{bahattn}
\newlabel{fig:globalatn}{{\caption@xref {fig:globalatn}{ on input line 254}}{9}{Effective Approaches to Attention Based Neural Machine Translation}{figure.caption.13}{}}
\newlabel{sub@fig:globalatn}{{}{9}{Effective Approaches to Attention Based Neural Machine Translation}{figure.caption.13}{}}
\newlabel{fig:localatn}{{\caption@xref {fig:localatn}{ on input line 261}}{9}{Effective Approaches to Attention Based Neural Machine Translation}{figure.caption.13}{}}
\newlabel{sub@fig:localatn}{{a}{9}{Effective Approaches to Attention Based Neural Machine Translation}{figure.caption.13}{}}
\newlabel{fig:iofeed}{{\caption@xref {fig:iofeed}{ on input line 268}}{9}{Effective Approaches to Attention Based Neural Machine Translation}{figure.caption.13}{}}
\newlabel{sub@fig:iofeed}{{b}{9}{Effective Approaches to Attention Based Neural Machine Translation}{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The model and the result from Neural Machine Translation by jointly learning to align and translate\relax }}{9}{figure.caption.13}}
\newlabel{fig:luong}{{5}{9}{The model and the result from Neural Machine Translation by jointly learning to align and translate\relax }{figure.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Alternatives for \(scores(h_t,\overline  {h_s})\)\relax }}{9}{table.caption.15}}
\newlabel{tab:scores}{{1}{9}{Alternatives for \(scores(h_t,\overline {h_s})\)\relax }{table.caption.15}{}}
\@writefile{toc}{\contentsline {paragraph}{Local Attention Model: }{9}{section*.16}}
\@writefile{toc}{\contentsline {paragraph}{Input Feeding Approach: }{9}{section*.17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Text Understanding with the Attention Sum Reader Network}{9}{subsection.4.3}}
\newlabel{sec:kadlec}{{4.3}{9}{Text Understanding with the Attention Sum Reader Network}{subsection.4.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Model: }{9}{section*.19}}
\citation{lin}
\citation{goognmt}
\citation{bahattn}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The structure of the Attention Sum Reader Network for text understanding.\relax }}{10}{figure.caption.18}}
\newlabel{fig:attnsum}{{6}{10}{The structure of the Attention Sum Reader Network for text understanding.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}A Structured Self-Attentive Sentence Embedding}{10}{subsection.4.4}}
\newlabel{sec:lin}{{4.4}{10}{A Structured Self-Attentive Sentence Embedding}{subsection.4.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Model: }{10}{section*.21}}
\@writefile{toc}{\contentsline {paragraph}{Penalization: }{10}{section*.22}}
\citation{adam}
\citation{subword}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  A sample model structure showing the sentence embedding model combined with a fully connected and softmax layer for sentiment analysis (a). The sentence embedding M is computed as multiple weighted sums of hidden states from a bidirectional LSTM \((h_1, ..., h_n)\), where the summation weights \((A_{i_1}, ..., A_{i_n})\) are computed in a way illustrated in (b). Blue colored shapes stand for hidden representations, and red colored shapes stand for weights, annotations, or input/output.\relax }}{11}{figure.caption.20}}
\newlabel{fig:attnsum}{{7}{11}{A sample model structure showing the sentence embedding model combined with a fully connected and softmax layer for sentiment analysis (a). The sentence embedding M is computed as multiple weighted sums of hidden states from a bidirectional LSTM \((h_1, ..., h_n)\), where the summation weights \((A_{i_1}, ..., A_{i_n})\) are computed in a way illustrated in (b). Blue colored shapes stand for hidden representations, and red colored shapes stand for weights, annotations, or input/output.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Google's Neural Machine Translation System}{11}{subsection.4.5}}
\newlabel{sec:goognmt}{{4.5}{11}{Google's Neural Machine Translation System}{subsection.4.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Google's Neural Machine Translation System. It contains Bi-LSTM in the first layer of encoder. It uses Residual Connections in the encoder and decoder. The model is also partioned into multiple GPUs to speed up training. To retain maximum parallelism, the bottom decoder layer output is used only for obtaining recurrent attention context, which is sent directly ot all the remaing decoder layers. \relax }}{12}{figure.caption.23}}
\newlabel{fig:goognmt}{{8}{12}{Google's Neural Machine Translation System. It contains Bi-LSTM in the first layer of encoder. It uses Residual Connections in the encoder and decoder. The model is also partioned into multiple GPUs to speed up training. To retain maximum parallelism, the bottom decoder layer output is used only for obtaining recurrent attention context, which is sent directly ot all the remaing decoder layers. \relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{12}{section.5}}
\newlabel{sec:conclusion}{{5}{12}{Conclusion}{section.5}{}}
\bibstyle{unsrt}
\bibdata{references}
\bibcite{salton}{{1}{}{{}}{{}}}
\bibcite{jones}{{2}{}{{}}{{}}}
\bibcite{jonesfre}{{3}{}{{}}{{}}}
\bibcite{benn}{{4}{}{{}}{{}}}
\bibcite{mikw2v}{{5}{}{{}}{{}}}
\bibcite{melamud}{{6}{}{{}}{{}}}
\bibcite{mikngs}{{7}{}{{}}{{}}}
\bibcite{suts}{{8}{}{{}}{{}}}
\bibcite{pos}{{9}{}{{}}{{}}}
\bibcite{senti}{{10}{}{{}}{{}}}
\bibcite{bahattn}{{11}{}{{}}{{}}}
\bibcite{luongatn}{{12}{}{{}}{{}}}
\bibcite{kadlec}{{13}{}{{}}{{}}}
\bibcite{cho}{{14}{}{{}}{{}}}
\bibcite{xuatn}{{15}{}{{}}{{}}}
\bibcite{lin}{{16}{}{{}}{{}}}
\bibcite{goognmt}{{17}{}{{}}{{}}}
\bibcite{subword}{{18}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{Appendices}{14}{section*.25}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Recurrent Neural Network}{14}{Appendix.1.A}}
\newlabel{sec:rnn}{{A}{14}{Recurrent Neural Network}{Appendix.1.A}{}}
\newlabel{eq:1}{{{1}}{14}{Recurrent Neural Network}{Appendix.1.A}{}}
\newlabel{eq:2}{{{2}}{14}{Recurrent Neural Network}{Appendix.1.A}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces A Recurrent Neural Network Unit\relax }}{14}{figure.caption.26}}
\newlabel{fig:rnn}{{9}{14}{A Recurrent Neural Network Unit\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Vanishing Gradients and Explosion Problems}{14}{Appendix.1.B}}
\newlabel{sec:van}{{B}{14}{Vanishing Gradients and Explosion Problems}{Appendix.1.B}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Gated Recurrent Units}{15}{Appendix.1.C}}
\newlabel{sec:gru}{{C}{15}{Gated Recurrent Units}{Appendix.1.C}{}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\newlabel{fig:gru}{{\caption@xref {fig:gru}{ on input line 514}}{16}{Long Short Term Memory}{figure.caption.27}{}}
\newlabel{sub@fig:gru}{{}{16}{Long Short Term Memory}{figure.caption.27}{}}
\newlabel{fig:lstm}{{\caption@xref {fig:lstm}{ on input line 521}}{16}{Long Short Term Memory}{figure.caption.27}{}}
\newlabel{sub@fig:lstm}{{a}{16}{Long Short Term Memory}{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Variants of RNN\relax }}{16}{figure.caption.27}}
\newlabel{fig:rnna}{{10}{16}{Variants of RNN\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Long Short Term Memory}{16}{Appendix.1.D}}
\newlabel{sec:lstm}{{D}{16}{Long Short Term Memory}{Appendix.1.D}{}}
