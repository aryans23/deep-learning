import tensorflow as tf\\
mnist = tf.keras.datasets.mnist\\
from keras.utils import np\_utils\\
import numpy as np\\

tf.logging.set\_verbosity(tf.logging.ERROR)\\

from tensorflow.examples.tutorials.mnist import input\_data\\
mnist = input\_data.read\_data\_sets("MNIST\_data", one\_hot=True)\\

\# Python optimisation variables\\
learning\_rate = 0.5\\
epochs = 10\\
batch\_size = 100\\

\# declare the training data placeholders\\
\# input x - for 28 x 28 pixels = 784\\
x = tf.placeholder(tf.float32, [None, 784])\\
\# now declare the output data placeholder - 10 digits\\
y = tf.placeholder(tf.float32, [None, 10])\\

\# now declare the weights connecting the input to the hidden layer\\
W1 = tf.Variable(tf.random\_normal([784, 600], stddev=0.03), name='W1')\\
b1 = tf.Variable(tf.random\_normal([600]), name='b1')\\
\# more layers\\
W11 = tf.Variable(tf.random\_normal([600, 500], stddev=0.03), name='W11')\\
b11 = tf.Variable(tf.random\_normal([500]), name='b11')\\
W12 = tf.Variable(tf.random\_normal([500, 300], stddev=0.03), name='W12')\\
b12 = tf.Variable(tf.random\_normal([300]), name='b12')\\
\# and the weights connecting the hidden layer to the output layer\\
W2 = tf.Variable(tf.random\_normal([300, 10], stddev=0.03), name='W2')\\
b2 = tf.Variable(tf.random\_normal([10]), name='b2')\\

\# calculate the output of the hidden layer\\
h1 = tf.add(tf.matmul(x,W1), b1)\\
a1 = tf.nn.relu(h1)\\
h11 = tf.add(tf.matmul(a1,W11), b11)\\
a11 = tf.nn.relu(h11)\\
h12 = tf.add(tf.matmul(a11,W12), b12)\\
a12 = tf.nn.relu(h12)\\

\# now calculate the hidden layer output - in this case, let's use a softmax activated\\
\# output layer\\
y\_ = tf.nn.softmax(tf.add(tf.matmul(a12, W2), b2))\\

y\_clipped = tf.clip\_by\_value(y\_, 1e-10, 0.9999999)\\
cross\_entropy = -tf.reduce\_mean(tf.reduce\_sum(y * tf.log(y\_clipped)\\
+ (1 - y) * tf.log(1 - y\_clipped), axis=1))\\

optimiser = tf.train.GradientDescentOptimizer(learning\_rate=learning\_rate).minimize(\\cross\_entropy)\\

\# finally setup the initialisation operator\\
init\_op = tf.global\_variables\_initializer()\\

\# define an accuracy assessment operation\\
correct\_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y\_, 1))\\
accuracy = tf.reduce\_mean(tf.cast(correct\_prediction, tf.float32))\\

\# start the session\\
with tf.Session() as sess:\\
\# initialise the variables\\
sess.run(init\_op)\\
total\_batch = int(len(mnist.train.labels) / batch\_size)\\
for epoch in range(epochs):\\
avg\_cost = 0\\
for i in range(total\_batch):\\
batch\_x, batch\_y = mnist.train.next\_batch(batch\_size=batch\_size)\\
\_, c = sess.run([optimiser, cross\_entropy], \\
feed\_dict={x: batch\_x, y: batch\_y})\\
avg\_cost += c / total\_batch\\
print("Epoch:", (epoch + 1), "cost =", "{:.3f}".format(avg\_cost))\\
print(sess.run(accuracy, feed\_dict={x: mnist.test.images, y: mnist.test.labels}))\\